{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f99c45b8-57e7-4aa3-a7a5-3d8978723710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "%run wikidata_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d49af804-2f6e-4319-912c-120490ee1b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-09 07:23:36.086263: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from spacy.matcher import Matcher \n",
    "import spacy_universal_sentence_encoder\n",
    "import claucy   \n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5622f764-f61c-436a-8a53-ec5fbeade3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f173432-f855-45fb-ba37-af9455a6c583",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "882f76b5-7e5d-4a07-ab69-6d7eb746798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = ['P530', 'P463', 'P150', 'P2936']\n",
    "\n",
    "extrs = {}\n",
    "for p in ps:\n",
    "    extrs[p] = pickle.load(open(f'models/logreg_{p}_2000.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8efe4db5-6a26-4180-b91f-5f3ebf486b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')\n",
    "claucy.add_to_pipe(nlp)\n",
    "use= spacy.load('en_use_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00f53287-0d45-49fa-a6e3-547dd1a570e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_pos_map2(pos):\n",
    "    if pos in [\"NOUN\", \"PRON\", \"PROPN\", \"NN\", \"NND\", \"NNPS\", \"NNS\", \"PRP\", \"PRP$\"]:\n",
    "        return 1\n",
    "    elif pos in [\"VERB\", \"MD\", \"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\"]:\n",
    "        return 2\n",
    "    elif pos in [\"ADV\", \"RB\", \"RBR\", \"RBS\", \"RP\"]:\n",
    "        return 3\n",
    "    elif pos in [\"ADJ\", \"JJ\", \"JJR\", \"JJS\"]:\n",
    "        return 4\n",
    "    elif pos in [\"NUM\", \"CD\"]:\n",
    "        return 5\n",
    "    elif pos == \"FW\":\n",
    "        return 6\n",
    "    else:\n",
    "        return 7 # everything else "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42d64d9f-4934-4e80-99e3-bb209b2e8a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_Xsents(sents, labels, nlp, use, limit=50):\n",
    "    assert(len(sents) == len(labels))\n",
    "    \n",
    "    n = len(sents)\n",
    "    n_fts = limit + limit + 512\n",
    "    # words + pos + universal sentence encoding\n",
    "    \n",
    "    X = np.zeros((n, n_fts))\n",
    "    sents_ = np.empty(n, dtype=object)\n",
    "\n",
    "    i = 0\n",
    "    for z, sent in enumerate(sents):\n",
    "        doc = nlp(sent)\n",
    "        if len(doc) > limit: continue #too long\n",
    "            \n",
    "        for k, tok in enumerate(doc):\n",
    "            X[i][k] = int.from_bytes(str(tok).encode(), 'big')\n",
    "            X[i][k + limit] = spacy_pos_map2(tok.pos_)\n",
    "        \n",
    "        sem = use(sent) #universal sentence encoding\n",
    "        X[i][2*limit:] = sem.vector\n",
    "\n",
    "        # label\n",
    "        sents_[i] = sent\n",
    "        i += 1\n",
    "\n",
    "    return X[:i], sents_[:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34da305c-ac83-4f2f-880f-0913ad61067f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['United States']\n"
     ]
    }
   ],
   "source": [
    "# list of entities to query\n",
    "\n",
    "entities = [\"United States\"]\n",
    "articles = []\n",
    "for e in entities:\n",
    "    l = search_wikipedia(e)\n",
    "    # print(l)\n",
    "    if l:\n",
    "        articles.append(l[0])\n",
    "\n",
    "print(articles)\n",
    "\n",
    "contents = []\n",
    "for a in articles:\n",
    "    try:\n",
    "        page = query_wikipedia(a)\n",
    "        contents.append(page.content)\n",
    "    except:\n",
    "        print(f\"{a} page not found\")\n",
    "\n",
    "# a little cleaning\n",
    "for c in contents:\n",
    "    i = c.find(\"== References ==\")\n",
    "    c_ = c[:i]\n",
    "    c_ = re.sub('==.*==', '', c_) # get rid of wikipedia section headers\n",
    "    c_ = re.sub('\\([^\\)]*\\)', '', c_) # get rid of everything between parentheses\n",
    "    \n",
    "\n",
    "    doc = nlp(c_)\n",
    "    sents = map(lambda s : str(s).replace(\"\\n\", \"\"), doc.sents)\n",
    "\n",
    "    # for s in list(sents)[:5]:\n",
    "    #     doc_s = nlp(s)\n",
    "    #     print(s)\n",
    "    #     propositions = doc_s._.clauses[0].to_propositions(as_text=True)\n",
    "    #     print(propositions)\n",
    "\n",
    "    sents = list(sents)\n",
    "    X, sents = sentences_to_Xsents(sents, len(sents)*[False], nlp, use, limit=50)\n",
    "    # for s in sents:\n",
    "        # doc_s = nlp(s)\n",
    "        # ent1, ent2 = get_entities(doc_s)\n",
    "        # rel = get_relation(doc_s)\n",
    "\n",
    "        # try:\n",
    "        #     Q1 = get_qid(ent1)\n",
    "        #     Q2 = get_qid(ent2)\n",
    "        #     P = get_pid_from_str(rel)\n",
    "        # except:\n",
    "        #     continue\n",
    "\n",
    "        # # print(Q1, P, Q2)\n",
    "            \n",
    "        # if check_triple(Q1, P, Q2):\n",
    "        #     x.append(s)\n",
    "        #     y.append(True)\n",
    "        # elif check_sp(Q1, P):\n",
    "        #     # print(Q1, P, Q2)\n",
    "        #     x.append(s)\n",
    "        #     y.append(False)\n",
    "        # else:\n",
    "        #     print(Q1, Q2, P)\n",
    "        #     print(ent1, ent2, rel)\n",
    "        #     pass\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4892170-780d-4081-88f4-ef5d2f0797d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = {}\n",
    "for p in ps:\n",
    "    ex = extrs[p]\n",
    "    y_pred = ex.predict(X)\n",
    "    y_preds[p] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d1ff308-f06b-4544-b184-66202bbd2364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The United States of America , commonly known as the United States  or America, is a country primarily located in North America.\n",
      "['P463']\n",
      "It consists of 50 states, a federal district, five major unincorporated territories, and nine Minor Outlying Islands.\n",
      "['P463', 'P150', 'P2936']\n",
      "It includes 326 Indian reservations.\n",
      "['P463']\n",
      "The U.S. is the world's third-largest country by land area, and by total area.\n",
      "['P150', 'P2936']\n",
      "It shares land borders with Canada to its north and with Mexico to its south and has maritime borders with the Bahamas, Cuba, Russia, and other nations.\n",
      "['P530', 'P463', 'P150']\n",
      "With a population of over 333 million, it is the most populous country in the Americas and the third-most populous in the world.\n",
      "['P463', 'P150']\n",
      "The national capital of the United States is Washington, D.C., and its most populous city and principal financial center is New York City.\n",
      "['P463', 'P2936']\n",
      "Indigenous peoples have inhabited the Americas for thousands of years.\n",
      "['P530', 'P463', 'P150', 'P2936']\n",
      "Beginning in 1607, British colonization led to the establishment of the Thirteen Colonies in what is now the Eastern United States.\n",
      "['P150', 'P2936']\n",
      "They clashed with the British Crown over taxation and political representation, which led to the American Revolution and the ensuing Revolutionary War.\n",
      "['P530', 'P463', 'P2936']\n",
      "The United States declared independence on July 4, 1776, becoming the first nation-state founded on Enlightenment principles of unalienable natural rights, consent of the governed, and republicanism.\n",
      "['P463']\n",
      "The country began expanding across North America, spanning the continent by 1848.\n",
      "['P530', 'P463', 'P150']\n",
      "Sectional division over slavery led to the secession of the Confederate States of America, which fought the remaining states of the Union during the American Civil War .\n",
      "['P530', 'P463', 'P2936']\n",
      "With the Union's victory and preservation, slavery was abolished nationally.\n",
      "['P463']\n",
      "By 1900, the United States had established itself as a great power, becoming the world's largest economy.\n",
      "['P463', 'P2936']\n",
      "After Japan's attack on Pearl Harbor in December 1941, the U.S. entered World War II on the side of the Allies.\n",
      "['P463', 'P2936']\n",
      "Following the Soviet Union's collapse and the end of the Cold War in the early 1990s, it emerged as the world's sole superpower.\n",
      "['P530', 'P463', 'P2936']\n",
      "The United States government is a federal presidential constitutional republic and liberal democracy with three separate branches of government: legislative, executive, and judicial.\n",
      "['P463', 'P2936']\n",
      "It has a bicameral national legislature composed of the House of Representatives, a lower house based on population; and the Senate, an upper house based on equal representation for each state.\n",
      "['P530', 'P463', 'P150', 'P2936']\n",
      "Many policy issues are decentralized at a state or local level, with widely differing laws by jurisdiction.\n",
      "['P463']\n"
     ]
    }
   ],
   "source": [
    "for i, s in enumerate(sents[:20]):\n",
    "    print(s)\n",
    "    hits = []\n",
    "    for p in ps:\n",
    "        if y_preds[p][i]:\n",
    "            hits.append(p)\n",
    "    print(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "05408b7e-a16f-4392-8260-50cd4c66c29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_rates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "256e58a2-021e-4022-b6cc-078fe5c230d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr = []\n",
    "for p in ps:\n",
    "    hr.append(sum(y_preds[p])/len(sents))\n",
    "hit_rates.append(hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04484705-0705-4c94-8a98-3a62890a4c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_rates = [[0.4543269230769231,\n",
    "  0.8533653846153846,\n",
    "  0.5889423076923077,\n",
    "  0.4254807692307692],\n",
    " [0.4004237288135593, 0.7521186440677966, 0.5190677966101694, 0.375],\n",
    " [0.42430703624733473,\n",
    "  0.8656716417910447,\n",
    "  0.6140724946695096,\n",
    "  0.3837953091684435],\n",
    " [0.43410852713178294,\n",
    "  0.8656330749354005,\n",
    "  0.6149870801033591,\n",
    "  0.3695090439276486]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1500ee8d-baa3-4357-8a41-d1767d50c9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, hr in enumerate(hit_rates):\n",
    "    hit_rates[i] = list(map(lambda r : round(r, 2), hr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42616574-4ebd-4aea-89e5-a70674172279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.45, 0.85, 0.59, 0.43],\n",
       " [0.4, 0.75, 0.52, 0.38],\n",
       " [0.42, 0.87, 0.61, 0.38],\n",
       " [0.43, 0.87, 0.61, 0.37]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b9fc20-76cf-498f-a60d-eac91e31df1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
