{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13a30e4d-9968-4911-b29c-7b5df924cbcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "%run wikidata_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e28b87db-f897-484b-8da2-21efc068bdb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-09 03:58:24.425972: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.matcher import Matcher "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b0d229b-4815-4af6-8722-ded81bb25f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2f45138-aa74-4ec5-9793-a937735ca087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbb7a6f2-cfab-4e52-9711-ee37728966dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "htm = open('text/text1.htm').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cba128a-231d-4fb3-b69d-b1f6e6fe5ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/14694482/converting-html-to-text-with-python\n",
    "soup = BeautifulSoup(htm)\n",
    "text = soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c04f6fc-e60a-4cde-8afd-e73a2b2535ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace(\"\\n\", \" \")\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6146cc-bf15-4ac5-b97f-0b71ebf2211e",
   "metadata": {},
   "source": [
    "doc = nlp(text)\n",
    "sents = list(doc.sents)\n",
    "sents = sents[1000:1010]\n",
    "for i, sent in enumerate(sents):\n",
    "    print(i, sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8434072d-5194-494d-a29f-9e9f47461027",
   "metadata": {},
   "source": [
    "nlp2 = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b942d4-1617-41e2-8b1e-ea52aa56115a",
   "metadata": {},
   "source": [
    "doc0 = nlp2(str(sents[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da7dc49-729e-4018-aebf-13af502b359b",
   "metadata": {},
   "source": [
    "for tok in doc0:\n",
    "  print(tok.text, \"...\", tok.dep_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08164510-950c-445d-88c9-ef805ba6b369",
   "metadata": {},
   "source": [
    "ONLY 1 SUB AND 1 OBJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f864a35-c24b-4536-b631-a0ae8ea78501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(doc):\n",
    "\n",
    "    # dep = map(lambda tok: tok.dep_, doc)\n",
    "    # subjs, objs = 0, 0\n",
    "    # for d in dep:\n",
    "    #     if 'obj' in d:\n",
    "    #         objs += 1\n",
    "    #     if 'subj' in d:\n",
    "    #         subjs += 1\n",
    "\n",
    "    # if objs + subjs != 2:\n",
    "    #     raise Exception(\"More than two entities found.\")\n",
    "    \n",
    "    \n",
    "    ## chunk 1\n",
    "    ent1 = \"\"\n",
    "    ent2 = \"\"\n",
    "    \n",
    "    prv_tok_dep = \"\"    # dependency tag of previous token in the sentence\n",
    "    prv_tok_text = \"\"   # previous token in the sentence\n",
    "    \n",
    "    prefix = \"\"\n",
    "    modifier = \"\"\n",
    "\n",
    "  #############################################################\n",
    "  \n",
    "    for tok in doc:\n",
    "    ## chunk 2\n",
    "    # if token is a punctuation mark then move on to the next token\n",
    "        if tok.dep_ != \"punct\":\n",
    "      # check: token is a compound word or not\n",
    "            if tok.dep_ == \"compound\":\n",
    "                prefix = tok.text\n",
    "                # if the previous word was also a 'compound' then add the current word to it\n",
    "                if prv_tok_dep == \"compound\":\n",
    "                    prefix = prv_tok_text + \" \"+ tok.text\n",
    "            \n",
    "            # check: token is a modifier or not\n",
    "            if tok.dep_.endswith(\"mod\") == True:\n",
    "                modifier = tok.text\n",
    "                # if the previous word was also a 'compound' then add the current word to it\n",
    "                if prv_tok_dep == \"compound\":\n",
    "                    modifier = prv_tok_text + \" \"+ tok.text\n",
    "            \n",
    "            ## chunk 3\n",
    "            if tok.dep_.find(\"subj\") == True:\n",
    "                ent1 = modifier +\" \"+ prefix + \" \"+ tok.text\n",
    "                prefix = \"\"\n",
    "                modifier = \"\"\n",
    "                prv_tok_dep = \"\"\n",
    "                prv_tok_text = \"\"      \n",
    "            \n",
    "            ## chunk 4\n",
    "            if tok.dep_.find(\"obj\") == True:\n",
    "                ent2 = modifier +\" \"+ prefix +\" \"+ tok.text\n",
    "            \n",
    "            ## chunk 5  \n",
    "            # update variables\n",
    "            prv_tok_dep = tok.dep_\n",
    "            prv_tok_text = tok.text\n",
    "  #############################################################\n",
    "\n",
    "    return [ent1.strip(), ent2.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2954beb0-1d6a-4b84-85aa-941271004e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relation(doc):\n",
    "    \n",
    "  # Matcher class object \n",
    "  matcher = Matcher(nlp.vocab)\n",
    "\n",
    "  #define the pattern \n",
    "  pattern = [{'DEP':'ROOT'}, \n",
    "            {'DEP':'prep','OP':\"?\"},\n",
    "            {'DEP':'agent','OP':\"?\"},  \n",
    "            {'POS':'ADJ','OP':\"?\"}] \n",
    "\n",
    "  matcher.add(\"matching_1\",[pattern]) \n",
    "\n",
    "  matches = matcher(doc)\n",
    "  k = len(matches) - 1\n",
    "\n",
    "  span = doc[matches[k][1]:matches[k][2]] \n",
    "\n",
    "  return(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a874289-9fe3-49a2-9e9c-610845925f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2004 Democratic National Convention',\n",
       " 'Timeline of the Barack Obama presidency (2013)',\n",
       " 'Capital Gazette shooting',\n",
       " \"Larry O'Brien\",\n",
       " 'Violence Against Women Act',\n",
       " 'Birmingham campaign',\n",
       " 'Timeline of the Barack Obama presidency (2009)',\n",
       " 'Democratic Party of Virginia',\n",
       " 'Thaddeus McCotter 2012 presidential campaign',\n",
       " 'Harris Insights & Analytics',\n",
       " 'Barack Obama Selma 50th anniversary speech',\n",
       " 'Timeline of the George H. W. Bush presidency',\n",
       " 'Black film',\n",
       " 'Timeline of the Barack Obama presidency (2011)',\n",
       " 'Lisa Murkowski',\n",
       " '2008 United States Senate elections',\n",
       " 'Bill Gates',\n",
       " 'List of African-American firsts',\n",
       " 'University of Chicago Laboratory Schools',\n",
       " 'Lead Belly',\n",
       " 'Rick Perry 2012 presidential campaign',\n",
       " 'Becoming (2020 documentary film)',\n",
       " 'Federal poverty level',\n",
       " '2015 Nobel Peace Prize',\n",
       " 'Bureau of Labor Statistics']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = query_wikipedia(\"Obama\")\n",
    "links = p.links\n",
    "# links = []\n",
    "random.sample(links, len(links)//100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e66e049a-b7af-4003-aa86-d782105a6660",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELSE\n",
      "Q76 P5059 Q4909834\n",
      "Obama served as civil rights lawyer\n",
      "FALSE\n",
      "Q76 P19 Q18094\n",
      "Obama born in Honolulu\n",
      "FALSE\n",
      "Q76 P2190 Q19822352\n",
      "Obama moved to stepfather\n",
      "ELSE\n",
      "Q9288 P1366 Q2439\n",
      "he continued 1980\n",
      "ELSE\n",
      "Q87167 P1433 Q186350\n",
      "manuscript published in Father\n",
      "FALSE\n",
      "Q76 P69 Q6581478\n",
      "Obama graduated from magna cum laude\n",
      "ELSE\n",
      "Q311681 P11176 Q7416\n",
      "who got Margaret Thatcher\n",
      "ELSE\n",
      "Q167109 P3254 Q1196074\n",
      "Jager proposed to him\n",
      "ELSE\n",
      "Q887314 P580 Q43959\n",
      "Bo joined by Sunny\n",
      "ELSE\n",
      "Q311681 P1343 Q9174\n",
      "who described religion\n",
      "ELSE\n",
      "Q311681 P3014 Q16970\n",
      "who were church\n",
      "ELSE\n",
      "Q51929447 P9883 Q16970\n",
      "she was church\n",
      "ELSE\n",
      "Q51929517 P7081 Q236\n",
      "they came to me\n",
      "ELSE\n",
      "Q257834 P562 Q257834\n",
      " Bank \n",
      "ELSE\n",
      "Q3975 P7113 Q12731\n",
      "case settled out court\n",
      "ELSE\n",
      "Q9288 P101 Q35127\n",
      "he filed website\n",
      "ELSE\n",
      "Q9288 P248 Q17422\n",
      "he stated same sex marriage\n",
      "ELSE\n",
      "Q9288 P460 Q17422\n",
      "he said same sex marriage\n",
      "ELSE\n",
      "Q15614918 P3344 Q2165493\n",
      "that vetoed pipeline\n",
      "ELSE\n",
      "Q10225 P10695 Q1996\n",
      "Congress introduced 2009\n",
      "ELSE\n",
      "Q1379733 P3254 Q851\n",
      "Obama administration proposed Saudi Arabia\n",
      "ELSE\n",
      "Q51929517 P178 Q1317\n",
      "they developed Osama bin Laden\n",
      "ELSE\n",
      "Q257834 P5008 Q257834\n",
      " On \n",
      "ELSE\n",
      "Q1379733 P4004 Q37230\n",
      "Obama administration shielded Central Intelligence Agency\n",
      "ELSE\n",
      "Q51929517 P2190 Q12060942\n",
      "they moved to Kalorama\n",
      "ELSE\n",
      "Q76 P7888 Q2297571\n",
      "Barack bought Wyc Grousbeck\n",
      "ELSE\n",
      "Q7478101 P8001 Q30461\n",
      "we endorsed president\n",
      "ELSE\n",
      "Q76 P9570 Q201788\n",
      "Obama notes historians\n",
      "ELSE\n",
      "Q76 P2919 Q973073\n",
      "Obama signed into Dodd\n",
      "ELSE\n",
      "Q257834 P1454 Q30461\n",
      " rights president\n",
      "FALSE\n",
      "Q15975388 P31 Q257834\n",
      "Obama Presidential Center is \n"
     ]
    }
   ],
   "source": [
    "# list of entities to query\n",
    "\n",
    "entities = [\"Obama\"]\n",
    "articles = []\n",
    "for e in entities:\n",
    "    l = search_wikipedia(e)\n",
    "    # print(l)\n",
    "    if l:\n",
    "        articles.append(l[0])\n",
    "\n",
    "# print(articles)\n",
    "\n",
    "contents = []\n",
    "for a in articles:\n",
    "    try:\n",
    "        page = query_wikipedia(a)\n",
    "        contents.append(page.content)\n",
    "    except:\n",
    "        print(f\"{a} page not found\")\n",
    "\n",
    "x, y = [], []\n",
    "# a little cleaning\n",
    "for c in contents:\n",
    "    i = c.find(\"== References ==\")\n",
    "    c_ = c[:i]\n",
    "    c_ = re.sub('==.*==', '', c_) # get rid of wikipedia section headers\n",
    "    c_ = re.sub('\\([^\\)]*\\)', '', c_) # get rid of everything between parentheses\n",
    "    \n",
    "\n",
    "    doc = nlp(c_)\n",
    "    sents = map(lambda s : str(s).replace(\"\\n\", \"\"), doc.sents)\n",
    "\n",
    "    for s in sents:\n",
    "        doc_s = nlp(s)\n",
    "        ent1, ent2 = get_entities(doc_s)\n",
    "        rel = get_relation(doc_s)\n",
    "\n",
    "        try:\n",
    "            Q1 = get_qid(ent1)\n",
    "            Q2 = get_qid(ent2)\n",
    "            P = get_pid_from_str(rel)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # print(Q1, P, Q2)\n",
    "            \n",
    "        if check_triple(Q1, P, Q2):\n",
    "            print(\"TRUE\")\n",
    "            print(Q1, P, Q2)\n",
    "            print(ent1, rel, ent2)\n",
    "            x.append(s)\n",
    "            y.append(True)\n",
    "        elif check_sp(Q1, P):\n",
    "            print(\"FALSE\")\n",
    "            print(Q1, P, Q2)\n",
    "            print(ent1, rel, ent2)\n",
    "            x.append(s)\n",
    "            y.append(False)\n",
    "        else:\n",
    "            print(\"ELSE\")\n",
    "            print(Q1, P, Q2)\n",
    "            print(ent1, rel, ent2)\n",
    "            pass\n",
    "\n",
    "# return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "084ed468-5098-462a-98db-eb4d07d45511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re.sub('\\([^\\)]*\\)', '', contents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d0d75f6-ce88-42a9-9075-6412e5a79215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Obama was born in Honolulu, Hawaii.',\n",
       " 'At the age of six, Obama and his mother had moved to Indonesia to join his stepfather.',\n",
       " 'Obama graduated from Harvard Law in 1991 with a Juris Doctor magna cum laude.',\n",
       " \"The Barack Obama Presidential Center is Obama's planned presidential library.\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1df0df40-7067-41e8-b03b-5b9af57f90e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, False, False]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4c17306d-cf5c-4384-a95a-0129ab6b8e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('presidential  library', '2021', 'began')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent1, ent2, rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "70e56470-d3cf-4c18-a73c-072746017b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Q30957', '48', 'year'), ('Q712764', '48', 'natural number'), ('Q8042637', 'XXXY syndrome', 'chromosomal anomaly of the aneuploidic type characterized by the presence of two extra X chromosomes in males'), ('Q1166570', '48', 'Wikimedia disambiguation page'), ('Q16926797', 'route 48', 'tram route in metropolitan Melbourne, Victoria, Australia')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Q30957'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_qid('48')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f088acfd-25f6-44ad-ae59-347fc061831d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[104], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m ent1, ent2 \u001b[38;5;241m=\u001b[39m get_entities(doc)\n\u001b[1;32m      4\u001b[0m rel \u001b[38;5;241m=\u001b[39m get_relation(doc)\n\u001b[0;32m----> 6\u001b[0m Q1 \u001b[38;5;241m=\u001b[39m \u001b[43mget_qid\u001b[49m\u001b[43m(\u001b[49m\u001b[43ment1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m Q2 \u001b[38;5;241m=\u001b[39m get_qid(ent2)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/var/folders/2t/krg9z5s10j965b3b574w37s00000gn/T/ipykernel_36959/754720121.py:4\u001b[0m, in \u001b[0;36mget_qid\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m      2\u001b[0m results \u001b[38;5;241m=\u001b[39m query_wikidata(make_query_for_qid(name))\n\u001b[1;32m      3\u001b[0m data \u001b[38;5;241m=\u001b[39m process_query_for_qid(results)\n\u001b[0;32m----> 4\u001b[0m qid \u001b[38;5;241m=\u001b[39m \u001b[43mget_qid_from_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m qid\n",
      "File \u001b[0;32m/var/folders/2t/krg9z5s10j965b3b574w37s00000gn/T/ipykernel_36959/1367243207.py:3\u001b[0m, in \u001b[0;36mget_qid_from_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_qid_from_data\u001b[39m(data):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(data)\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "s = 'His presidential library in Chicago began construction in 2021'\n",
    "doc = nlp(s)\n",
    "ent1, ent2 = get_entities(doc)\n",
    "rel = get_relation(doc)\n",
    "\n",
    "Q1 = get_qid(ent1)\n",
    "Q2 = get_qid(ent2)\n",
    "try:\n",
    "    P = get_pid_from_str(rel)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bb05a11d-5877-4530-b1b8-722a82029636",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q146'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fc2fb257-0754-49fb-a805-ee445c888467",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b54ef5f7-db0c-4596-aef5-d00cec7a671c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barack ... compound\n",
      "Hussein ... nsubj\n",
      "Obama ... compound\n",
      "II ... appos\n",
      "( ... punct\n",
      "  ... dep\n",
      "bə ... amod\n",
      "- ... punct\n",
      "RAHK ... amod\n",
      "hoo ... amod\n",
      "- ... punct\n",
      "SAYN ... nmod\n",
      "oh ... compound\n",
      "- ... punct\n",
      "BAH ... compound\n",
      "- ... punct\n",
      "mə ... parataxis\n",
      "; ... punct\n",
      "born ... advcl\n",
      "August ... npadvmod\n",
      "4 ... nummod\n",
      ", ... punct\n",
      "1961 ... nummod\n",
      ") ... punct\n",
      "is ... ROOT\n",
      "an ... det\n",
      "American ... amod\n",
      "politician ... attr\n",
      "who ... nsubj\n",
      "served ... relcl\n",
      "as ... prep\n",
      "the ... det\n",
      "44th ... amod\n",
      "president ... pobj\n",
      "of ... prep\n",
      "the ... det\n",
      "United ... compound\n",
      "States ... pobj\n",
      "from ... prep\n",
      "2009 ... pobj\n",
      "to ... prep\n",
      "2017 ... pobj\n",
      ". ... punct\n"
     ]
    }
   ],
   "source": [
    "for tok in doc:\n",
    "  print(tok.text, \"...\", tok.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988bfade-200f-4f66-9ecd-75cde9251917",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
